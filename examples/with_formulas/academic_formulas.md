# Engram: 基于可扩展查表的条件记忆架构（公式详解版）

**论文标题**：Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models
**论文链接**：[GitHub](https://github.com/deepseek-ai/Engram)
**作者团队**：北京大学 & DeepSeek-AI

> 本文为 **academic 风格 + 公式讲解** 示例。在完整论文解读基础上，对核心公式进行符号级详解。

---

## 摘要

本文提出 Engram，一种基于条件记忆（Conditional Memory）的新型稀疏架构。该方法将 N-gram 查表机制与 Transformer 主干网络相结合，通过可扩展的哈希检索实现 O(1) 复杂度的静态知识获取，同时保留 Transformer 的动态推理能力。实验表明，在等参数、等 FLOPs 条件下，Engram-27B 在知识任务（MMLU +3.4）、推理任务（BBH +5.0）和长上下文任务（NIAH 84.2→97.0）上均显著优于 MoE 基线。

## 1. 研究背景与动机

### 1.1 当前大语言模型的局限性

现有大语言模型（LLMs）将所有知识编码于密集参数中，推理时需激活完整的计算路径。这种设计存在以下核心问题：

**计算效率问题**：静态知识（实体名称、固定搭配、事实性信息）与动态推理（逻辑推演、数学证明）共享相同的计算资源。获取"中国的首都是北京"这一简单事实，需要与复杂推理任务相同的计算开销。

**知识更新困难**：模型的知识完全编码于参数中，修改特定知识点需要重新训练整个模型，缺乏模块化的知识管理机制。

**内存效率低下**：大量参数用于存储可查表的静态模式，而非真正需要参数化的推理能力。

### 1.2 N-gram 模型的启示

传统 N-gram 语言模型通过统计 n 个连续 token 的共现概率进行预测。其优势在于 O(1) 的查表复杂度，但受限于组合爆炸问题——n 增大时，可能的 N-gram 数量呈指数增长（V^n，其中 V 为词汇表大小）。

Engram 的核心思想是：**将 N-gram 的高效查表与 Transformer 的上下文建模相结合**，用查表处理静态模式，用计算处理动态推理。

## 2. Engram 架构设计

### 2.1 整体架构

Engram 在标准 Transformer 的特定层引入条件记忆模块（Conditional Memory Module），与 MoE 专家并行部署：

![Engram 架构图](../style_comparison/images/853aef65961c6b9429369ceb08f0accc4a3021ce66d5ad2e0df9aeb3f12d479e.jpg)

架构包含三个核心组件：N-gram 哈希检索、上下文门控机制、残差融合。

### 2.2 N-gram 哈希检索

对于位置 t 的输入 token，提取其前 k 个 token 组成 N-gram（实验中 k=2 或 k=3）。通过多头哈希函数将 N-gram 映射至嵌入表：

$$e_t = \sum_{h=1}^{H} E_h[\text{hash}_h(x_{t-k:t})]$$

#### 📐 公式符号详解

| 符号 | 含义 | 说明 |
|------|------|------|
| $e_t$ | 检索得到的嵌入向量 | 最终输出，维度为 embed_dim，将被送入门控机制 |
| $H$ | 哈希头数 | 通常为 4-8，多头设计降低冲突概率 |
| $E_h$ | 第 h 个嵌入表 | 形状为 [table_size, head_dim]，每个头独立存储 |
| $\text{hash}_h(\cdot)$ | 第 h 个哈希函数 | 将 N-gram 映射为整数索引，范围 [0, table_size) |
| $x_{t-k:t}$ | N-gram 序列 | 当前 token $x_t$ 及其前 k 个 token 组成的序列 |
| $k$ | N-gram 长度减 1 | k=2 表示 3-gram，k=3 表示 4-gram |
| $[\cdot]$ | 索引操作 | 根据哈希值从嵌入表中取出对应行向量 |

**直观理解**：把"首都在"这个 3-gram 通过哈希函数变成一个数字（比如 12345），然后去嵌入表里查第 12345 行，取出对应的向量。多个头各自查表后求和。

**复杂度分析**：检索复杂度为 O(H)，与序列长度无关。由于 H 是常数（通常 4-8），因此是 O(1)。

### 2.3 上下文门控机制

查表得到的嵌入是上下文无关的静态信息。为处理语言的多义性（如"苹果"可指水果或公司），引入上下文感知的门控机制：

$$g_t = \sigma(W_g \cdot [h_t; e_t])$$
$$o_t = g_t \cdot W_v \cdot e_t$$

#### 📐 公式符号详解

| 符号 | 含义 | 说明 |
|------|------|------|
| $g_t$ | 门控标量 | 取值范围 [0,1]，控制记忆的使用程度 |
| $\sigma(\cdot)$ | sigmoid 激活函数 | $\sigma(x) = \frac{1}{1+e^{-x}}$，将输出压缩到 [0,1] |
| $W_g$ | 门控权重矩阵 | 形状为 [1, 2×embed_dim]，可学习参数 |
| $h_t$ | 当前位置的隐藏状态 | 已通过注意力层聚合全局上下文信息 |
| $[h_t; e_t]$ | 向量拼接操作 | 将隐藏状态和记忆向量在最后一维拼接，维度变为 2×embed_dim |
| $o_t$ | 门控后的输出 | 将被通过残差连接加到主干网络 |
| $W_v$ | 值投影矩阵 | 形状为 [embed_dim, embed_dim]，将记忆投影到输出空间 |

**直观理解**：
- 当 $g_t \to 1$：完全信任记忆（上下文和记忆一致）
- 当 $g_t \to 0$：忽略记忆（上下文和记忆冲突）

**例子**：在"苹果公司的股价"语境中，检索"苹果"可能得到水果相关的嵌入，但 $h_t$ 包含"公司""股价"等上下文信息，门控会自动趋近于 0，抑制水果语义。

### 2.4 残差融合

门控后的记忆通过残差连接融合至主干网络：

$$h_t' = h_t + o_t$$

#### 📐 公式符号详解

| 符号 | 含义 | 说明 |
|------|------|------|
| $h_t'$ | 融合后的隐藏状态 | 将继续送入后续的 FFN/MoE 层 |
| $h_t$ | 原始隐藏状态 | 来自注意力层的输出 |
| $o_t$ | 门控后的记忆输出 | 经过门控筛选的有效记忆信息 |

**设计意图**：残差连接确保即使 Engram 模块完全失效（$o_t = 0$），模型仍能正常工作。这提高了训练稳定性，也便于模块化调试。

随后继续正常的 Attention 和 FFN/MoE 计算。

## 3. 稀疏分配策略

### 3.1 MoE 与 Engram 的参数分配

在固定参数预算下，MoE 专家与 Engram 记忆的分配比例直接影响模型性能。系统实验揭示了 **U 型曲线** 特征：

![稀疏分配实验](../style_comparison/images/a44c062d736c965077330a673248cfad4dfe5d671d50efcd868ddeb8dfec2342.jpg)

设总稀疏参数为 $P$，则分配公式为：

$$P = P_{\text{MoE}} + P_{\text{Engram}}$$

#### 📐 最优配置分析

| 配置 | MoE 占比 | Engram 占比 | 特点 |
|------|---------|------------|------|
| 纯 MoE | 100% | 0% | 缺乏记忆模块，用计算模拟查表，效率低 |
| 纯 Engram | 0% | 100% | 缺乏条件计算，无法处理动态推理 |
| **最优配置** | 75-80% | 20-25% | 两者互补，性能最佳 |

### 3.2 无限内存扩展性

右图显示了固定计算量下仅扩展 Engram 容量的实验。验证损失呈现 log-linear 下降趋势：

$$\mathcal{L} \propto -\log(P_{\text{Engram}})$$

表明 Engram 具有良好的扩展性——增加内存可持续提升性能，且不增加推理计算量。

## 4. 实验结果与分析

### 4.1 主要基准测试

基于最优分配策略，训练 Engram-27B 与 MoE-27B 基线进行严格对比（等参数、等 FLOPs）：

| 任务类别 | 基准测试 | MoE-27B | Engram-27B | 提升 |
|---------|---------|---------|------------|------|
| 知识密集型 | MMLU | 71.2 | 74.6 | +3.4 |
| 知识密集型 | CMMLU | 68.9 | 72.9 | +4.0 |
| 通用推理 | BBH | 62.4 | 67.4 | +5.0 |
| 通用推理 | ARC-C | 84.1 | 87.8 | +3.7 |
| 代码生成 | HumanEval | 58.5 | 61.5 | +3.0 |
| 数学推理 | MATH | 35.2 | 37.6 | +2.4 |
| 长上下文 | NIAH (MQ) | 84.2 | 97.0 | +12.8 |

知识任务的提升符合预期。推理和代码任务的显著提升需要进一步分析。

### 4.2 推理任务受益机制：等效网络加深

LogitLens 和 CKA 分析揭示了推理任务受益的内在机制：

![LogitLens 和 CKA 分析](../style_comparison/images/3d7e70042b917eec0e3a9f6de58dd189cd1e655af876a05c5727ec5c932cad3f.jpg)

**LogitLens 分析**（左图）：测量各层隐状态与最终预测的 KL 散度。Engram 模型在早期层即达到低 KL 散度，表明特征组合过程显著加速。

**CKA 相似度分析**（中、右图）：Engram 第 5 层的表示相当于 MoE 第 12 层的表示。Engram 将静态模式识别从早期层"卸载"，**等效于增加 7 层网络深度**。

这解释了推理任务的提升：更多的网络层数可用于复杂推理，而非简单的模式识别。

### 4.3 功能分离验证

消融实验验证了 Engram 与 Transformer 主干的功能分离：

![Engram 消融实验](../style_comparison/images/df4aa413292b494b89fb94ab5d3a5d3d4af0e0801a2f2fc98a1433189fc41f27.jpg)

推理时完全关闭 Engram 模块：
- **事实知识任务**（TriviaQA、NaturalQuestions）：性能下降至 29-44%
- **阅读理解任务**（C3、RACE）：性能保持在 81-93%

结果表明 Engram 主要承担知识存储功能，而上下文依赖的任务主要依赖 Transformer 注意力机制，两者功能分离清晰。

### 4.4 门控激活模式可视化

门控机制的可视化分析进一步验证了 Engram 的工作模式：

![门控可视化](../style_comparison/images/72aafc116c62cdb1ea0b6fc393193ba8491b768e3ddb9a29cfe3ea9298c4b450.jpg)

高激活区域集中在：
- **命名实体**："Alexander the Great"、"the Milky Way"
- **固定搭配**："By the way"、"Princess of Wales"
- **中文成语与专名**："四大发明"、"张仲景"

这些静态模式被成功识别并通过查表获取，验证了架构设计的有效性。

## 5. 系统实现与效率优化

### 5.1 确定性索引的优势

与 MoE 的动态路由不同，Engram 的查表索引**仅取决于输入 token**，与隐藏状态无关。这一特性带来显著的系统优势：

![系统实现](../style_comparison/images/6408d0b8fea236ab4df4272a3366766b9f044cd1a5b589faf7a13e42d1f27df1.jpg)

**预取优化**：当前层计算时，可并行预取下一 Engram 层所需的嵌入向量。

**异构存储**：嵌入表可部署于 CPU 内存甚至 SSD，通过通信-计算重叠隐藏数据传输延迟。

### 5.2 性能评估

将 100B 参数的嵌入表部署于 CPU 内存（通过 PCIe 传输），推理吞吐量仅下降 3%。结合自然语言的 Zipf 分布特性（少量高频模式占据大部分文本），可进一步采用分层缓存策略：高频嵌入置于 GPU HBM，低频嵌入置于 CPU 内存或 SSD。

## 6. 讨论与展望

### 6.1 架构设计的启示

Engram 的成功表明：**架构设计应匹配任务的内在结构**。语言建模本质上是异构的——静态知识适合查表，动态推理需要计算。统一处理不如分而治之。

### 6.2 与人脑机制的类比

Engram 架构与人脑的功能分区存在有趣的类比：海马体负责陈述性记忆，前额叶负责推理决策。Engram 可视为为 Transformer 引入的"人工海马体"。

### 6.3 未来研究方向

- **多模态扩展**：视觉模型是否存在类似的"静态模式 vs 动态推理"区分
- **知识编辑**：利用 Engram 的模块化特性实现高效的知识更新
- **稀疏性配比的自动学习**：根据任务特性自适应调整 MoE/Engram 比例

## 7. 结论

本文提出 Engram 架构，通过引入条件记忆机制实现了静态知识与动态推理的功能分离。实验证明该架构在多个基准测试上显著优于同等规模的 MoE 模型，且具有良好的系统效率和扩展性。Engram 为大语言模型架构设计开辟了新的研究方向。

---

**参考文献**

[1] DeepSeek-AI. Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models. 2025.

*代码开源地址：https://github.com/deepseek-ai/Engram*

---

*本文展示了 academic 风格 + 公式讲解功能。在完整论文解读基础上，对核心公式进行符号级详解，适合需要深入理解技术细节的读者。*

# Engram 深度解析 - academic 风格

**论文标题**：Conditional Memory via Scalable Lookup: A New Axis of Sparsity for Large Language Models
**作者团队**：北京大学 & DeepSeek-AI

---

## 摘要

本文提出 Engram，一种基于条件记忆（Conditional Memory）的稀疏架构。该方法将 N-gram 查表机制与 Transformer 主干网络相结合，通过可扩展的哈希检索实现 O(1) 复杂度的静态知识获取。

## 背景与动机

现有大语言模型将所有知识编码于密集参数中，推理时需激活全部计算路径。这种设计存在两个核心问题：

1. **计算效率低下**：静态知识（如实体、固定搭配）与动态推理共享相同的计算资源
2. **知识更新困难**：修改特定知识需要重新训练整个模型

## 方法

### 条件记忆模块

Engram 在 Transformer 特定层引入条件记忆模块，包含三个核心组件：

**N-gram 哈希检索**：将输入 token 序列的 N-gram 通过多头哈希函数映射至嵌入表，检索复杂度为 O(1)。

**上下文门控机制**：利用当前隐藏状态 h_t 与检索得到的记忆向量 e_t 计算门控标量 g_t，实现上下文感知的记忆融合。

**残差连接**：门控后的记忆通过残差路径融合至主干网络。

### 稀疏分配策略

实验表明，MoE 与 Engram 的最优分配比例约为 75-80% : 20-25%。

## 实验结果

在严格等参数、等 FLOPs 条件下，Engram-27B 相比 MoE-27B 基线：

| 任务类型 | 基准测试 | 提升幅度 |
|----------|----------|----------|
| 知识密集型 | MMLU | +3.4 |
| 推理任务 | BBH | +5.0 |
| 长上下文 | NIAH | +12.8 |

## 结论

Engram 通过引入条件记忆机制，实现了静态知识与动态推理的功能分离，为大语言模型架构设计提供了新的研究方向。
